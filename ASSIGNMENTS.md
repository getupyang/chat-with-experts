# Chat-with-Experts å®è·µä½œä¸šé›†

**è®¾è®¡ç†å¿µ**: å‚è€ƒStanford CS336,é€šè¿‡hands-onå®è·µå»ºç«‹æ·±åº¦è®¤çŸ¥

**éš¾åº¦æ¢¯åº¦**: Assignment 1-2 (åŸºç¡€) â†’ Assignment 3-4 (è¿›é˜¶) â†’ Assignment 5-6 (é«˜çº§)

---

## ğŸ“š Assignment 1: Prompt Archaeology (åŸºç¡€,8å°æ—¶)

### å­¦ä¹ ç›®æ ‡
- ç†è§£promptå·¥ç¨‹çš„æœ¬è´¨æ˜¯"æ‰¾åˆ°AIçš„å¤±è´¥æ¨¡å¼,ç„¶åé’ˆå¯¹æ€§ä¿®å¤"
- æŒæ¡"å¯¹æ¯”åˆ†æ â†’ æ‰¾gap â†’ ä¿®prompt"çš„è¿­ä»£æ–¹æ³•
- å»ºç«‹"æ•°æ®é©±åŠ¨"çš„promptä¼˜åŒ–ä¹ æƒ¯

### ä»»åŠ¡æè¿°

ç»™ä½ 5ä¸ª"bad outputs"(ç³»ç»Ÿå®é™…ç”Ÿæˆçš„ä½è´¨é‡è¾“å‡º),ä½ çš„ä»»åŠ¡æ˜¯:
1. åˆ†æä¸ºä»€ä¹ˆè¿™ä¸ªè¾“å‡ºqualityä½
2. è¯†åˆ«promptä¸­çš„é—®é¢˜
3. ä¿®æ”¹prompt
4. é‡æ–°ç”Ÿæˆ,éªŒè¯æ˜¯å¦æ”¹è¿›

---

#### Case 1: Context Mismatch - ä¸“å®¶é€‰æ‹©é”™è¯¯

**User Query**:
```
æˆ‘æ˜¯ä¸€ä¸ªsoloç‹¬ç«‹å¼€å‘è€…,æœ€è¿‘åœ¨è€ƒè™‘è¦ä¸è¦ç»™æˆ‘çš„SaaSäº§å“åŠ AIåŠŸèƒ½ã€‚
æˆ‘çš„äº§å“ç°åœ¨æœ‰1000ä¸ªå…è´¹ç”¨æˆ·,ä½†åªæœ‰20ä¸ªä»˜è´¹ç”¨æˆ·ã€‚
æˆ‘æ²¡æœ‰å›¢é˜Ÿ,æ‰€æœ‰å¼€å‘éƒ½æ˜¯æˆ‘è‡ªå·±åšã€‚
```

**Bad Output** (å½“å‰ç³»ç»Ÿç”Ÿæˆ):
```
**Experts Selected**:
1. Sam Altman (OpenAI CEO)
2. Elon Musk (Tesla/SpaceX CEO)

**Sam Altman**: AIæ˜¯æœªæ¥çš„è¶‹åŠ¿,æ¯ä¸ªäº§å“éƒ½åº”è¯¥æ‹¥æŠ±AIã€‚æˆ‘å»ºè®®ä½ ...

**Elon Musk**: First principles thinkingå‘Šè¯‰æˆ‘ä»¬,AIä¼šrevolutionizeæ‰€æœ‰è¡Œä¸š...
```

**é—®é¢˜åˆ†æ**:
```
[ ä½ çš„åˆ†æ ]

æç¤º:
- ä¸“å®¶æ˜¯å¦matchç”¨æˆ·çš„context?
- Sam Altmanå’ŒElon Muské€‚åˆç»™solo devå»ºè®®å—?
- ç”¨æˆ·çœŸæ­£éœ€è¦ä»€ä¹ˆç±»å‹çš„å»ºè®®?
```

**Promptä¿®æ”¹**:
```
[ ç²˜è´´ä½ ä¿®æ”¹åçš„expert recruiter prompt ]

å…³é”®æ”¹åŠ¨è¯´æ˜:
1. [æ”¹åŠ¨ç‚¹1]: ä¸ºä»€ä¹ˆåŠ è¿™ä¸ªinstruction?
2. [æ”¹åŠ¨ç‚¹2]: ...
```

**éªŒè¯ç»“æœ**:
```
é‡æ–°è¿è¡Œåçš„è¾“å‡º:

**Experts Selected**:
1. [æ–°ä¸“å®¶åå•]
2. ...

[ ç²˜è´´æ–°çš„å¯¹è¯è¾“å‡º ]

æ”¹è¿›è¯„ä¼°:
- Expert Match Score: ä¹‹å‰ 3/10 â†’ ç°åœ¨ __/10
- æ˜¯å¦è§£å†³äº†context mismatché—®é¢˜? [æ˜¯/å¦]
- è¿˜æœ‰ä»€ä¹ˆé—®é¢˜? [...]
```

---

#### Case 2: Lack of Actionability - å»ºè®®å¤ªæŠ½è±¡

**User Query**:
```
æˆ‘æ˜¯AIäº§å“ç»ç†,å›¢é˜Ÿ5ä¸ªäºº,éœ€è¦æ”¹è¿›æˆ‘ä»¬çš„LLMäº§å“çš„è¿­ä»£æµç¨‹ã€‚
ç°åœ¨çš„é—®é¢˜æ˜¯è¿­ä»£å¤ªæ…¢,ä¸€ä¸ªåŠŸèƒ½è¦2å‘¨æ‰èƒ½ä¸Šçº¿ã€‚
```

**Bad Output**:
```
**Expert 1**: ä½ éœ€è¦å»ºç«‹æ›´é«˜æ•ˆçš„workflowã€‚

**Expert 2**: æˆ‘åŒæ„ã€‚æ•æ·å¼€å‘å¾ˆé‡è¦,è¦å¤šåšæµ‹è¯•ã€‚

**Expert 3**: å¦å¤–æ•°æ®é©±åŠ¨ä¹Ÿå¾ˆå…³é”®,è¦å…³æ³¨metricsã€‚
```

**é—®é¢˜åˆ†æ**:
```
[ ä½ çš„åˆ†æ ]

æç¤º:
- è¿™äº›å»ºè®®å…·ä½“å—?ç”¨æˆ·èƒ½ç«‹å³æ‰§è¡Œå—?
- "æ›´é«˜æ•ˆçš„workflow"å…·ä½“æ˜¯ä»€ä¹ˆ?
- "å¤šåšæµ‹è¯•"è¦æ€ä¹ˆåš?
- ç¼ºå°‘ä»€ä¹ˆä¿¡æ¯?
```

**Promptä¿®æ”¹**:
```
[ ç²˜è´´ä½ ä¿®æ”¹åçš„dialogue generation prompt ]

å…³é”®æ”¹åŠ¨:
1. åŠ å…¥"Actionability Template" - å¼ºåˆ¶è¦æ±‚specific steps
2. åŠ å…¥"No Vague Language" rule
3. ...
```

**éªŒè¯ç»“æœ**:
```
[ ç²˜è´´æ–°è¾“å‡º,åº”è¯¥åŒ…å«å…·ä½“çš„æ­¥éª¤ã€æ—¶é—´çº¿ã€å·¥å…·å»ºè®® ]

æ”¹è¿›è¯„ä¼°:
- Actionability Score: ä¹‹å‰ 3/10 â†’ ç°åœ¨ __/10
- ç”¨æˆ·èƒ½å¦åœ¨Monday morningçŸ¥é“åšä»€ä¹ˆ? [æ˜¯/å¦]
```

---

#### Case 3: Expert Redundancy - ä¸“å®¶è§‚ç‚¹é‡å¤

**Bad Output**:
```
**Expert 1**: æˆ‘è®¤ä¸ºå¾®æœåŠ¡çš„ä¼˜åŠ¿æ˜¯scalabilityå’Œflexibility...

**Expert 2**: æˆ‘åŒæ„Expert 1çš„è§‚ç‚¹,å¾®æœåŠ¡ç¡®å®æœ‰å¾ˆå¥½çš„scalability...

**Expert 3**: ä¸¤ä½ä¸“å®¶çš„æ´è§å¾ˆæ·±åˆ»ã€‚è¡¥å……ä¸€ç‚¹,å¾®æœåŠ¡çš„flexibilityå¾ˆé‡è¦...
```

**é—®é¢˜**: 3ä¸ªä¸“å®¶éƒ½åœ¨è¯´åŒæ ·çš„äº‹æƒ…,æµªè´¹tokens

**ä½ çš„ä»»åŠ¡**:
- åˆ†æä¸ºä»€ä¹ˆä¼šå‡ºç°redundancy
- ä¿®æ”¹prompt,å¼ºåˆ¶ä¸“å®¶æä¾›unique perspectives
- éªŒè¯ä¿®æ”¹åæ¯ä¸ªä¸“å®¶æœ‰ä¸åŒçš„è§’åº¦

---

#### Case 4: Hallucination - ä¸“å®¶åå­—ç¼–é€ 

**Bad Output**:
```
**Experts Selected**:
1. æ¢æ–‡å³° (AIæŠ€æœ¯ä¸“å®¶)  â† ç”¨æˆ·æƒ³è¦çš„çœŸå®äººç‰©
2. å¼ æ™“æ˜ (äº§å“ç»ç†)    â† å¯èƒ½æ˜¯ç¼–é€ çš„
3. Deep Wu (å´ç¦)       â† åå­—æ‹¼å‡‘,çœŸå®äººç‰©æ˜¯å´æ‰¿éœ–
```

**é—®é¢˜**: AIç¼–é€ æˆ–æ··æ·†äº†ä¸“å®¶åå­—

**ä½ çš„ä»»åŠ¡**:
- åœ¨promptä¸­åŠ å…¥verificationæœºåˆ¶
- åŠ å…¥famous expertä¼˜å…ˆè§„åˆ™
- æµ‹è¯•èƒ½å¦å‡å°‘hallucination

---

#### Case 5: Missing User Context - æ²¡ç†è§£ç”¨æˆ·çœŸå®éœ€æ±‚

**User Query**:
```
æˆ‘çš„äº§å“å·²ç»ä¸Šçº¿3ä¸ªæœˆäº†,æœ‰1000ä¸ªç”¨æˆ·,ä½†conversion rateå¾ˆä½(2%)ã€‚
ä¸çŸ¥é“æ˜¯äº§å“åŠŸèƒ½é—®é¢˜è¿˜æ˜¯å®šä»·é—®é¢˜ã€‚
```

**Bad Output**:
```
[ ä¸“å®¶ç»™äº†å¾ˆå¤šæå‡conversion rateçš„é€šç”¨æ–¹æ³•,ä½†æ²¡äººé—®"æ˜¯å“ªä¸ªç¯èŠ‚æµå¤±çš„?" ]
```

**é—®é¢˜**: ä¸“å®¶æ²¡æœ‰å…ˆclarifyé—®é¢˜,ç›´æ¥ç»™genericå»ºè®®

**ä½ çš„ä»»åŠ¡**:
- è®©ä¸“å®¶å…ˆ"è¯Šæ–­"å†"å¼€è¯æ–¹"
- ä¿®æ”¹prompt,åŠ å…¥"Ask clarifying questions"æœºåˆ¶
- éªŒè¯ä¸“å®¶æ˜¯å¦èƒ½è¯†åˆ«éœ€è¦æ›´å¤šä¿¡æ¯

---

### æäº¤è¦æ±‚

åˆ›å»ºæ–‡ä»¶: `assignments/assignment1_prompt_archaeology.md`

**æ ¼å¼**:
```markdown
# Assignment 1: Prompt Archaeology

## Case 1: Context Mismatch
### é—®é¢˜åˆ†æ
[...]

### Promptä¿®æ”¹
[...]

### éªŒè¯ç»“æœ
[...]

### åæ€
[ ä»è¿™ä¸ªcaseå­¦åˆ°äº†ä»€ä¹ˆ?æœªæ¥å¦‚ä½•é¿å…ç±»ä¼¼é—®é¢˜? ]

---

## Case 2: Lack of Actionability
[åŒä¸Šæ ¼å¼]

---

[ 5ä¸ªcasesçš„å®Œæ•´åˆ†æ ]

---

## æ€»ç»“

### æœ€é‡è¦çš„3ä¸ªlearnings:
1. [...]
2. [...]
3. [...]

### ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘:
[åŸºäºè¿™5ä¸ªcases,ä½ è®¤ä¸ºå½“å‰promptçš„æœ€å¤§é—®é¢˜æ˜¯ä»€ä¹ˆ?]
```

### è¯„åˆ†æ ‡å‡†

| ç»´åº¦ | æè¿° | åˆ†å€¼ |
|------|------|------|
| **é—®é¢˜åˆ†ææ·±åº¦** | æ˜¯å¦è¯†åˆ«å‡ºæ ¹æœ¬åŸå› (ä¸æ˜¯è¡¨é¢ç°è±¡) | 30% |
| **Promptä¿®æ”¹åˆç†æ€§** | æ”¹åŠ¨æ˜¯å¦é’ˆå¯¹æ€§å¼º,ä¸æ˜¯randomè¯•é”™ | 30% |
| **éªŒè¯æœ‰æ•ˆæ€§** | æ˜¯å¦çœŸçš„æ”¹è¿›äº†,æœ‰before/afterå¯¹æ¯” | 25% |
| **åæ€è´¨é‡** | æ˜¯å¦æç‚¼å‡ºå¯å¤ç”¨çš„åŸåˆ™ | 15% |

**Passæ ‡å‡†**: 5ä¸ªcasesä¸­è‡³å°‘3ä¸ªæœ‰æ˜æ˜¾æ”¹è¿›(+3åˆ†ä»¥ä¸Š)

---

## ğŸ“š Assignment 2: Build a Judge (è¿›é˜¶,10å°æ—¶)

### å­¦ä¹ ç›®æ ‡
- ç†è§£LLM-as-a-Judgeçš„è®¾è®¡åŸåˆ™
- æŒæ¡å¦‚ä½•å®šä¹‰å¯é‡åŒ–çš„è¯„æµ‹æ ‡å‡†
- å»ºç«‹"è¯„æµ‹å…ˆè¡Œ"çš„å¼€å‘ä¹ æƒ¯

### èƒŒæ™¯

ä½ å·²ç»æœ‰2ä¸ªjudges (actionability, expert-division),ç°åœ¨éœ€è¦æ„å»ºç¬¬3ä¸ª:
**Context-Match Judge** - è¯„æµ‹ä¸“å®¶æ˜¯å¦åŒ¹é…ç”¨æˆ·çš„context

---

### Part 1: å®šä¹‰è¯„æµ‹æ ‡å‡† (2å°æ—¶)

**ä»»åŠ¡**: å†™ä¸€ä¸ªè¯¦ç»†çš„rubric

```markdown
# Context-Match Judge Rubric

## è¯„åˆ†æ ‡å‡† (0-10åˆ†)

### 10åˆ† (Perfect Match):
- æ¯ä¸ªä¸“å®¶éƒ½æœ‰ç±»ä¼¼contextçš„ç»éªŒ(å¦‚:solo devåŒ¹é…solo dev)
- ä¸“å®¶çš„å»ºè®®è€ƒè™‘äº†ç”¨æˆ·çš„èµ„æºé™åˆ¶
- æ²¡æœ‰"å¤§å…¬å¸æ–¹æ³•ç”¨åœ¨å°å›¢é˜Ÿ"çš„mismatch
- Example: [ä¸¾ä¸€ä¸ª10åˆ†çš„ä¾‹å­]

### 7-9åˆ† (Good Match):
- å¤§éƒ¨åˆ†ä¸“å®¶matchç”¨æˆ·context
- å¶å°”æœ‰è½»å¾®mismatchä½†ä¸å½±å“å»ºè®®è´¨é‡
- Example: [ä¸¾ä¸€ä¸ª8åˆ†çš„ä¾‹å­]

### 4-6åˆ† (Partial Match):
- éƒ¨åˆ†ä¸“å®¶match,éƒ¨åˆ†ä¸match
- å»ºè®®ä¸­æœ‰æ˜æ˜¾çš„context gap
- Example: [ä¸¾ä¸€ä¸ª5åˆ†çš„ä¾‹å­]

### 1-3åˆ† (Poor Match):
- å¤šæ•°ä¸“å®¶ä¸matchç”¨æˆ·context
- å»ºè®®æ˜æ˜¾ä¸é€‚ç”¨(å¦‚å¤§å‚æ–¹æ³•ç»™indie dev)
- Example: [ä¸¾ä¸€ä¸ª2åˆ†çš„ä¾‹å­]

### 0åˆ† (Complete Mismatch):
- æ‰€æœ‰ä¸“å®¶éƒ½ä¸match
- æˆ–è€…ä¸“å®¶èº«ä»½æœ¬èº«å°±é”™äº†(å¦‚è´¢åŠ¡ä¸“å®¶è®¨è®ºæŠ€æœ¯é—®é¢˜)
- Example: [ä¸¾ä¸€ä¸ª0åˆ†çš„ä¾‹å­]
```

**æäº¤**: `assignments/assignment2_context_match_rubric.md`

---

### Part 2: å®ç°Judge (4å°æ—¶)

**ä»»åŠ¡**: å®ç° `eval/judges/context-match-judge.ts`

```typescript
import { GoogleGenerativeAI } from "@google/generative-ai";

interface ContextMatchInput {
  userQuery: string;
  userContext: string;  // ç”¨æˆ·çš„è§’è‰²ã€èµ„æºã€é˜¶æ®µç­‰
  selectedExperts: Array<{
    name: string;
    title: string;
    reason: string;
  }>;
  dialogue: string;  // å®Œæ•´çš„å¯¹è¯å†…å®¹
}

interface ContextMatchOutput {
  score: number;  // 0-10
  analysis: {
    matchedExperts: string[];  // å“ªäº›ä¸“å®¶match
    mismatchedExperts: string[];  // å“ªäº›ä¸“å®¶ä¸match
    contextGaps: string[];  // å…·ä½“çš„context gap
    evidence: string[];  // æ”¯æŒåˆ¤æ–­çš„å…·ä½“evidence
  };
  feedback: string;  // ç»™ç³»ç»Ÿå¼€å‘è€…çš„æ”¹è¿›å»ºè®®
}

export async function judgeContextMatch(
  input: ContextMatchInput
): Promise<ContextMatchOutput> {
  // TODO: ä½ çš„å®ç°

  const prompt = `
  ä½ æ˜¯ä¸€ä¸ªexpert judge,è¯„æµ‹AIä¸“å®¶åœ†æ¡Œçš„ä¸“å®¶é€‰æ‹©æ˜¯å¦åŒ¹é…ç”¨æˆ·çš„contextã€‚

  [ æ’å…¥ä½ åœ¨Part 1è®¾è®¡çš„rubric ]

  ç”¨æˆ·Query: ${input.userQuery}
  ç”¨æˆ·Context: ${input.userContext}
  é€‰æ‹©çš„ä¸“å®¶: ${JSON.stringify(input.selectedExperts)}
  å¯¹è¯å†…å®¹: ${input.dialogue}

  è¯·è¯„åˆ†å¹¶ç»™å‡ºè¯¦ç»†åˆ†æã€‚è¾“å‡ºJSONæ ¼å¼ã€‚
  `;

  // TODO: è°ƒç”¨Gemini API
  // TODO: Parseè¾“å‡º
  // TODO: è¿”å›ç»“æ„åŒ–ç»“æœ
}
```

**å…³é”®è¦æ±‚**:
1. å¿…é¡»ä½¿ç”¨few-shot examples(è‡³å°‘3ä¸ªgood + 3ä¸ªbad)
2. è¾“å‡ºå¿…é¡»æ˜¯structured JSON
3. å¿…é¡»ç»™å‡ºå…·ä½“evidence(ä¸æ˜¯ç¬¼ç»Ÿçš„"ä¸åŒ¹é…")

---

### Part 3: Calibration (2å°æ—¶)

**ä»»åŠ¡**: åœ¨20ä¸ªcasesä¸Šæµ‹è¯•ä½ çš„judge,ä¸äººå·¥è¯„åˆ†å¯¹æ¯”

åˆ›å»ºæ–‡ä»¶: `assignments/assignment2_calibration_results.md`

```markdown
# Context-Match Judge Calibration Results

## Methodology
- Test set: 20ä¸ªgolden cases
- Human raters: æˆ‘è‡ªå·±(æˆ–1-2ä¸ªæœ‹å‹)
- æ¯ä¸ªcaseå…ˆäººå·¥æ‰“åˆ†,å†ç”¨judgeæ‰“åˆ†

## Results

| Case ID | Human Score | Judge Score | Diff | Agreement |
|---------|-------------|-------------|------|-----------|
| case-001 | 8 | 7 | -1 | âœ… Close |
| case-002 | 3 | 5 | +2 | âŒ Mismatch |
| ... | ... | ... | ... | ... |

## Statistical Analysis

- **Pearson Correlation**: 0.xx (ç›®æ ‡ > 0.75)
- **Mean Absolute Error**: x.x (ç›®æ ‡ < 1.5)
- **Agreement Rate** (Â±1åˆ†å†…): xx% (ç›®æ ‡ > 80%)

## Error Analysis

### Judgeæ‰“åˆ†è¿‡é«˜çš„cases:
- Case-002: Judgeç»™äº†5åˆ†,ä½†äººå·¥åªç»™3åˆ†
- åŸå› åˆ†æ: [Judgeæ²¡å‘ç°XXè¿™ä¸ªcontext gap]
- ä¿®å¤æ–¹æ¡ˆ: [åœ¨promptä¸­åŠ å¼ºXXçš„æ£€æŸ¥]

### Judgeæ‰“åˆ†è¿‡ä½çš„cases:
- Case-007: Judgeç»™äº†4åˆ†,ä½†äººå·¥ç»™äº†7åˆ†
- åŸå› åˆ†æ: [Judgeå¯¹"éƒ¨åˆ†åŒ¹é…"è¿‡äºä¸¥æ ¼]
- ä¿®å¤æ–¹æ¡ˆ: [è°ƒæ•´rubricçš„4-6åˆ†æ ‡å‡†]

## Iteration Log

### V1 (åˆå§‹ç‰ˆæœ¬):
- Correlation: 0.65
- é—®é¢˜: å¯¹"famous but irrelevant"çš„ä¸“å®¶è¿‡äºå®½å®¹

### V2 (æ”¹è¿›å):
- Correlation: 0.78 âœ…
- æ”¹åŠ¨: åŠ å…¥"context over fame"è§„åˆ™

### V3 (æœ€ç»ˆç‰ˆæœ¬):
- Correlation: 0.82 âœ…
- MAE: 1.2 âœ…
```

---

### Part 4: æ’°å†™Judgeæ–‡æ¡£ (2å°æ—¶)

**ä»»åŠ¡**: ä¸ºå…¶ä»–å¼€å‘è€…å†™ä½¿ç”¨æ–‡æ¡£

åˆ›å»ºæ–‡ä»¶: `eval/judges/README_CONTEXT_MATCH.md`

```markdown
# Context-Match Judge ä½¿ç”¨æ–‡æ¡£

## ç”¨é€”
è¯„æµ‹ä¸“å®¶é€‰æ‹©æ˜¯å¦åŒ¹é…ç”¨æˆ·çš„å…·ä½“context(è§’è‰²ã€èµ„æºã€é˜¶æ®µ)

## ä½¿ç”¨æ–¹æ³•

\`\`\`typescript
import { judgeContextMatch } from './context-match-judge';

const result = await judgeContextMatch({
  userQuery: "...",
  userContext: "ç‹¬ç«‹å¼€å‘è€…,6ä¸ªæœˆrunway",
  selectedExperts: [...],
  dialogue: "..."
});

console.log(result.score);  // 8
console.log(result.analysis.mismatchedExperts);  // []
\`\`\`

## è¯„åˆ†è§£é‡Š

| Score | å«ä¹‰ | ä½•æ—¶å‡ºç° |
|-------|------|---------|
| 9-10 | Perfect match | ä¸“å®¶å®Œç¾åŒ¹é…ç”¨æˆ·å¤„å¢ƒ |
| 7-8 | Good match | è½»å¾®mismatchä½†ä¸å½±å“è´¨é‡ |
| 4-6 | Partial match | éƒ¨åˆ†ä¸“å®¶ä¸åˆé€‚ |
| 1-3 | Poor match | å¤šæ•°ä¸“å®¶contexté”™è¯¯ |
| 0 | Complete mismatch | ä¸“å®¶å®Œå…¨ä¸ç›¸å…³ |

## å¸¸è§é—®é¢˜

### Q: Judgeç»™äº†ä½åˆ†,ä½†æˆ‘è§‰å¾—ä¸“å®¶æŒºåˆé€‚çš„?
A: æ£€æŸ¥`analysis.contextGaps`,çœ‹å…·ä½“æ˜¯å“ªé‡Œmismatchã€‚å¸¸è§æƒ…å†µ:
- "å¤§å…¬å¸CEOç»™indie devå»ºè®®" - å³ä½¿å»ºè®®æ­£ç¡®,contextä¸match
- "é€€ä¼‘ä¸“å®¶ç»™ç°å½¹é—®é¢˜å»ºè®®" - ä¿¡æ¯å¯èƒ½è¿‡æ—¶

### Q: Judgeçš„åˆ†æ•°å’Œäººå·¥è¯„åˆ†å·®å¼‚>2åˆ†?
A: å¯èƒ½éœ€è¦re-calibrationã€‚æ”¶é›†è¿™äº›cases,æ”¹è¿›rubricã€‚

## å·²çŸ¥å±€é™

1. **Famous Expert Bias**: Judgeæœ‰æ—¶ä¼šå› ä¸ºä¸“å®¶famouså°±ç»™é«˜åˆ†,å³ä½¿contextä¸match
   - Mitigation: åœ¨promptä¸­å¼ºè°ƒ"context over fame"

2. **Partial Contextæƒ…å†µ**: å¦‚æœuser contextä¿¡æ¯ä¸å…¨,Judgeå¯èƒ½æ— æ³•å‡†ç¡®è¯„ä¼°
   - Mitigation: åœ¨è¿™ç§æƒ…å†µä¸‹ç»™ä¸­ç­‰åˆ†(5-6),å¹¶åœ¨feedbackä¸­è¯´æ˜

## Changelog

- v1.0 (2025-11-27): åˆå§‹ç‰ˆæœ¬,correlation 0.65
- v1.1 (2025-11-28): åŠ å…¥few-shot examples,correlationæå‡åˆ°0.78
- v1.2 (2025-11-29): è°ƒæ•´rubric,correlation 0.82
```

---

### æäº¤æ¸…å•

- [ ] `assignments/assignment2_context_match_rubric.md`
- [ ] `eval/judges/context-match-judge.ts` (å¯è¿è¡Œçš„ä»£ç )
- [ ] `assignments/assignment2_calibration_results.md`
- [ ] `eval/judges/README_CONTEXT_MATCH.md`

### è¯„åˆ†æ ‡å‡†

| ç»´åº¦ | åˆ†å€¼ |
|------|------|
| Rubricæ¸…æ™°åº¦(æ˜¯å¦æœ‰clear criteria) | 20% |
| å®ç°è´¨é‡(ä»£ç å¯è¿è¡Œ,è¾“å‡ºæ­£ç¡®) | 30% |
| Calibration(correlation > 0.75) | 30% |
| æ–‡æ¡£å®Œæ•´æ€§ | 20% |

**Passæ ‡å‡†**: Correlation > 0.75 ä¸” MAE < 1.5

---

## ğŸ“š Assignment 3: Data Flywheel (è¿›é˜¶,12å°æ—¶)

### å­¦ä¹ ç›®æ ‡
- ç†è§£"ç”¨æˆ·åé¦ˆ â†’ æ•°æ®æ”¶é›† â†’ è¯„æµ‹ â†’ æ”¹è¿›"çš„é—­ç¯
- æŒæ¡å¦‚ä½•ä»çœŸå®ç”¨æˆ·è·å–æœ‰ä»·å€¼çš„feedback
- å»ºç«‹"æ•°æ®é©±åŠ¨è¿­ä»£"çš„å·¥ä½œæµ

### Part 1: æ”¶é›†çœŸå®ç”¨æˆ·åé¦ˆ (4å°æ—¶)

**ä»»åŠ¡**: æ‰¾10ä¸ªçœŸå®ç”¨æˆ·,è®©ä»–ä»¬è¯•ç”¨ä½ çš„äº§å“

**æ­¥éª¤**:

1. **æ‹›å‹Ÿç”¨æˆ·** (1h):
   - ç›®æ ‡: 10ä¸ªçœŸå®ç”¨æˆ·(æœ‹å‹ã€Twitterã€Redditç­‰)
   - æ ‡å‡†: å¿…é¡»æ˜¯ç›®æ ‡ç”¨æˆ·(åˆ›ä¸šè€…/PM/å¼€å‘è€…)

2. **ç”¨æˆ·æµ‹è¯•** (2h):
   ```
   ç»™æ¯ä¸ªç”¨æˆ·:
   1. è®©ä»–ä»¬é—®1ä¸ªçœŸå®çš„é—®é¢˜
   2. çœ‹å®Œè¾“å‡ºå,ç«‹å³é—®:
      - "è¿™ä¸ªå›ç­”æœ‰ç”¨å—?" (1-10åˆ†)
      - "æœ€æ»¡æ„çš„æ˜¯ä»€ä¹ˆ?"
      - "æœ€ä¸æ»¡æ„çš„æ˜¯ä»€ä¹ˆ?"
      - "å¦‚æœé‡æ–°æ¥ä¸€æ¬¡,ä½ ä¼šé—®ä»€ä¹ˆ?"
   3. è®°å½•æ‰€æœ‰åé¦ˆ
   ```

3. **æ•´ç†æ•°æ®** (1h):
   åˆ›å»ºæ–‡ä»¶: `data/user_feedback_10.jsonl`
   ```jsonl
   {"user_id": "user_001", "query": "...", "score": 7, "satisfied": "å¤šè§†è§’å¾ˆå¥½", "unsatisfied": "å¤ªæŠ½è±¡,ç¼ºä¹å…·ä½“æ­¥éª¤", "improved_query": "..."}
   {"user_id": "user_002", ...}
   ```

---

### Part 2: åˆ†æåé¦ˆæ¨¡å¼ (3å°æ—¶)

**ä»»åŠ¡**: ä»10ä¸ªåé¦ˆä¸­æ‰¾åˆ°common patterns

åˆ›å»ºæ–‡ä»¶: `assignments/assignment3_feedback_analysis.md`

```markdown
# ç”¨æˆ·åé¦ˆåˆ†æ

## æ•°æ®æ¦‚è§ˆ
- æ€»ç”¨æˆ·æ•°: 10
- å¹³å‡åˆ†: x.x / 10
- åˆ†æ•°åˆ†å¸ƒ:
  - 9-10åˆ†: xäºº
  - 7-8åˆ†: xäºº
  - 4-6åˆ†: xäºº
  - 1-3åˆ†: xäºº

## æ»¡æ„ç‚¹åˆ†æ (Affinity Mapping)

Top 3æœ€å¸¸æåˆ°çš„ä¼˜ç‚¹:
1. "å¤šè§†è§’" - 6äººæåˆ°
2. "å…·ä½“å»ºè®®" - 4äººæåˆ°
3. "ä¸“å®¶åŒ¹é…å¥½" - 3äººæåˆ°

## ä¸æ»¡æ„ç‚¹åˆ†æ

Top 3æœ€å¸¸æŠ±æ€¨çš„é—®é¢˜:
1. "å¤ªæŠ½è±¡,ç¼ºä¹actionable steps" - 5äºº
2. "ä¸“å®¶é€‰çš„ä¸å¯¹" - 3äºº
3. "å¤ªæ…¢" - 2äºº

## æ ¹å› åˆ†æ

### Problem 1: "å¤ªæŠ½è±¡"
**Evidence**:
- User #2: "å‘Šè¯‰æˆ‘'éœ€è¦æ³¨æ„é£é™©'ä½†æ²¡è¯´å…·ä½“é£é™©"
- User #5: "å»ºè®®'ä¼˜åŒ–æµç¨‹'ä½†æ²¡è¯´æ€ä¹ˆä¼˜åŒ–"

**Root Cause**: Promptç¼ºä¹"Actionability Template"

**Failed Cases**:
- case_user_002: Expertè¯´"éœ€è¦åšå¸‚åœºè°ƒç ”"ä½†æ²¡è¯´å…·ä½“æ€ä¹ˆåš
- case_user_005: Expertè¯´"ä¼˜åŒ–å·¥ä½œæµ"ä½†æ²¡ç»™æ­¥éª¤

### Problem 2: "ä¸“å®¶é€‰çš„ä¸å¯¹"
**Evidence**:
- User #3: "ç»™æˆ‘æ¨èäº†Sam Altman,ä½†æˆ‘æ˜¯solo dev"
- User #7: "ä¸“å®¶éƒ½æ˜¯å¤§å…¬å¸çš„,ä¸ç†è§£æˆ‘çš„èµ„æºé™åˆ¶"

**Root Cause**: Expert recruiteræ²¡æœ‰å¼ºåˆ¶context match

**Failed Cases**:
- case_user_003: ç»™indie devæ¨èäº†å¤§å…¬å¸CEO
- case_user_007: ç»™æ—©æœŸåˆ›ä¸šè€…æ¨èäº†æˆç†Ÿå…¬å¸çš„æ–¹æ³•
```

---

### Part 3: é’ˆå¯¹æ€§æ”¹è¿›Prompt (3å°æ—¶)

**ä»»åŠ¡**: åŸºäºåé¦ˆ,ä¿®æ”¹promptè§£å†³top 2é—®é¢˜

```markdown
# Prompt Iteration Log

## Issue #1: "å¤ªæŠ½è±¡" - Actionabilityä¸è¶³

### Before (å½“å‰prompt):
\`\`\`
[å½“å‰çš„dialogue generation promptç‰‡æ®µ]
\`\`\`

### After (æ”¹è¿›å):
\`\`\`
[æ–°çš„prompt,åŠ å…¥Actionability Template:]

When giving advice, you MUST follow this format:
1. **Context**: ä¸ºä»€ä¹ˆè¿™ä¸ªå»ºè®®é€‚åˆè¿™ä¸ªç”¨æˆ·(not generic)
2. **Specific Steps**: 3-5ä¸ªå¯æ‰§è¡Œçš„æ­¥éª¤(not "éœ€è¦åšXX")
   - Step 1: [Verb] [Specific Action] [Timeline]
   - Example: "æœ¬å‘¨å†…,ç”¨Hotjarå½•åˆ¶10ä¸ªç”¨æˆ·session"
3. **Success Metric**: æ€ä¹ˆåˆ¤æ–­åšå¯¹äº†
4. **Common Pitfall**: æœ€å®¹æ˜“çŠ¯çš„é”™è¯¯

Banned phrases:
âŒ "éœ€è¦æ³¨æ„..."
âŒ "åº”è¯¥æå‡..."
âŒ "è¦å…³æ³¨..."

Required patterns:
âœ… "å…·ä½“æ¥è¯´,ä½ è¦..."
âœ… "ç¬¬ä¸€æ­¥,æœ¬å‘¨å†…..."
âœ… "æˆåŠŸæ ‡å‡†æ˜¯..."
\`\`\`

### Why this works:
[è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªæ”¹åŠ¨èƒ½è§£å†³é—®é¢˜]

---

## Issue #2: "ä¸“å®¶é€‰çš„ä¸å¯¹" - Context Mismatch

### Before:
[...]

### After:
[åŠ å…¥æ›´å¼ºçš„context matchè§„åˆ™]

### Why this works:
[...]
```

---

### Part 4: A/B TestéªŒè¯æ”¹è¿› (2å°æ—¶)

**ä»»åŠ¡**: ç”¨åŒæ ·çš„10ä¸ªqueries,æµ‹è¯•æ–°æ—§ç‰ˆæœ¬

åˆ›å»ºæ–‡ä»¶: `assignments/assignment3_ab_test_results.md`

```markdown
# A/B Test Results: V2 (old) vs V3 (new)

## Test Setup
- Test queries: 10ä¸ª(æ¥è‡ªç”¨æˆ·åé¦ˆçš„çœŸå®queries)
- Version A (baseline): V2 with old prompts
- Version B (treatment): V3 with improved prompts

## Results

| Query ID | V2 Score | V3 Score | Delta | Improved? |
|----------|----------|----------|-------|-----------|
| query_001 | 6 | 8 | +2 | âœ… |
| query_002 | 5 | 7 | +2 | âœ… |
| query_003 | 7 | 7 | 0 | - |
| ... | ... | ... | ... | ... |

## Statistical Summary

- **Mean improvement**: +x.x points
- **Win rate**: x/10 queries improved
- **Regression**: x/10 queries got worse
- **No change**: x/10 queries same

## Dimension Analysis

| Dimension | V2 Average | V3 Average | Improvement |
|-----------|------------|------------|-------------|
| Actionability | 5.2 | 7.8 | +2.6 âœ… |
| Context Match | 6.5 | 8.1 | +1.6 âœ… |
| Overall | 6.1 | 7.5 | +1.4 âœ… |

## Case Studies

### Biggest Improvement: Query #2 (5 â†’ 8, +3)
**Query**: "æˆ‘æ˜¯solo dev,è¯¥ä¸è¯¥åŠ AIåŠŸèƒ½?"

**V2 Output Problem**:
- ä¸“å®¶è¯´"AIæ˜¯è¶‹åŠ¿,åº”è¯¥å…³æ³¨"
- å¤ªabstract,æ²¡æœ‰å…·ä½“å»ºè®®

**V3 Output Improvement**:
- ä¸“å®¶è¯´"ç¬¬ä¸€æ­¥:æœ¬å‘¨åšä¸ªlanding pageæµ‹è¯•éœ€æ±‚"
- ç»™äº†3-step plan with timeline

**Why it worked**: Actionability templateå¼ºåˆ¶äº†å…·ä½“æ­¥éª¤

---

### Regression Case: Query #7 (7 â†’ 6, -1)
**Query**: [...]

**Why it got worse**: [åˆ†æä¸ºä»€ä¹ˆæ”¹è¿›å¯¼è‡´äº†è¿™ä¸ªcaseå˜å·®]

**Lesson learned**: [å¦‚ä½•é¿å…ç±»ä¼¼regression]
```

---

### æäº¤æ¸…å•

- [ ] `data/user_feedback_10.jsonl`
- [ ] `assignments/assignment3_feedback_analysis.md`
- [ ] `assignments/assignment3_prompt_improvements.md`
- [ ] `assignments/assignment3_ab_test_results.md`

### è¯„åˆ†æ ‡å‡†

| ç»´åº¦ | åˆ†å€¼ |
|------|------|
| åé¦ˆæ•°æ®è´¨é‡(çœŸå®ç”¨æˆ·,è¯¦ç»†è®°å½•) | 25% |
| åˆ†ææ·±åº¦(æ‰¾åˆ°root cause,ä¸æ˜¯è¡¨é¢ç°è±¡) | 25% |
| Promptæ”¹è¿›åˆç†æ€§(é’ˆå¯¹æ€§å¼º) | 25% |
| A/B testç»“æœ(æœ‰æ˜æ˜¾improvement) | 25% |

**Passæ ‡å‡†**: A/B testæ˜¾ç¤ºå¹³å‡improvement > 1.0åˆ†,ä¸”æ— major regression

---

## ğŸ“š Assignment 4: Competitive Deep Dive (é«˜çº§,10å°æ—¶)

### ä»»åŠ¡æè¿°

é€‰æ‹©ä¸€ä¸ªç«å“(æ¨è: Deep Researchæˆ–Perplexity),åšæ·±åº¦æ‹†è§£åˆ†æã€‚

### Part 1: Product Teardown (4h)

**åˆ›å»º**: `assignments/assignment4_competitive_teardown.md`

**åˆ†æç»´åº¦**:

1. **æ ¸å¿ƒæŠ€æœ¯æ¶æ„**:
   - ç”¨ä»€ä¹ˆæ¨¡å‹?(å¦‚ä½•æ¨æµ‹)
   - Multi-agentè¿˜æ˜¯single-shot?
   - æœ‰æœç´¢å—?æœ‰å¤šå°‘steps?

2. **Prompt Engineering**:
   - é€šè¿‡è¯•æ¢æ€§é—®é¢˜,reverse engineerä»–ä»¬çš„prompt
   - Example:æ•…æ„é—®edge case,çœ‹å¦‚ä½•å¤„ç†

3. **ç”¨æˆ·ä½“éªŒ**:
   - å“åº”é€Ÿåº¦
   - è¾“å‡ºæ ¼å¼
   - äº¤äº’æµç¨‹

4. **å¼ºé¡¹ä¸å¼±é¡¹**:
   - åœ¨ä»€ä¹ˆåœºæ™¯æ˜æ˜¾ä¼˜äºä½ çš„äº§å“?
   - åœ¨ä»€ä¹ˆåœºæ™¯ä¸å¦‚ä½ ?

### Part 2: Feature Gap Analysis (3h)

**ä»»åŠ¡**: åˆ—å‡ºç«å“æœ‰è€Œä½ æ²¡æœ‰çš„features,è¯„ä¼°æ˜¯å¦åº”è¯¥åš

```markdown
# Feature Gap Analysis: Chat-with-Experts vs Deep Research

| Feature | ä»–ä»¬æœ‰ | æˆ‘ä»¬æœ‰ | æ˜¯å¦åº”è¯¥åš? | ä¼˜å…ˆçº§ | å·¥ä½œé‡ |
|---------|--------|--------|------------|--------|--------|
| æœç´¢å¼•ç”¨ | âœ… | âŒ | ? | ? | ? |
| Multi-step reasoning | âœ… | Partially | ? | ? | ? |
| ... | ... | ... | ... | ... | ... |

## Feature #1: æœç´¢å¼•ç”¨

**æè¿°**: Deep Researchä¼šæœç´¢æœ€æ–°ä¿¡æ¯å¹¶ç»™å‡ºå¼•ç”¨

**Pros**(å¦‚æœæˆ‘ä»¬åš):
- å¯ä»¥å¤„ç†éœ€è¦æœ€æ–°ä¿¡æ¯çš„queries
- å¢åŠ credibility(å¯éªŒè¯)

**Cons**(å¦‚æœæˆ‘ä»¬åš):
- å¢åŠ å“åº”æ—¶é—´(+5s)
- åç¦»æ ¸å¿ƒå®šä½(æˆ‘ä»¬æ˜¯"è§†è§’æ¨¡æ‹Ÿ"ä¸æ˜¯"ä¿¡æ¯æ£€ç´¢")

**å†³ç­–**: âŒ ä¸åš
**ç†ç”±**: ä¸åœ¨æˆ‘ä»¬çš„core value propä¸Šã€‚ç”¨æˆ·éœ€è¦æœç´¢æ—¶,åº”è¯¥ç”¨Perplexityã€‚

---

## Feature #2: Multi-step reasoning

**æè¿°**: Deep Researchä¼šåˆ†å¤šæ­¥thinking

**Pros**:
- å¯ä»¥å¤„ç†æ›´å¤æ‚çš„é—®é¢˜
- æ€è€ƒè¿‡ç¨‹æ›´é€æ˜

**Cons**:
- æˆ‘ä»¬å·²ç»æœ‰Director-Actoræ¨¡å¼,æ˜¯å¦ä¸€ç§multi-step

**å†³ç­–**: âœ… æ”¹è¿›ç°æœ‰çš„CoTæœºåˆ¶
**ç†ç”±**: æå‡ç°æœ‰æ¶æ„,è€Œä¸æ˜¯ç…§æ¬ç«å“

---

[å¯¹æ¯ä¸ªfeature gapåšç±»ä¼¼åˆ†æ]
```

### Part 3: æˆ˜ç•¥å®šä½å»ºè®® (3h)

**åŸºäºä»¥ä¸Šåˆ†æ,æ’°å†™æˆ˜ç•¥å®šä½å»ºè®®**

```markdown
# æˆ˜ç•¥å®šä½å»ºè®®

## æ ¸å¿ƒé—®é¢˜: æˆ‘ä»¬åº”è¯¥å’ŒDeep Researchç«äº‰å—?

**ç­”æ¡ˆ**: âŒ ä¸åº”è¯¥ç›´æ¥ç«äº‰

**ç†ç”±**:
1. Deep Researchçš„æ ¸å¿ƒä»·å€¼æ˜¯"å…¨é¢è°ƒç ”",æˆ‘ä»¬çš„æ ¸å¿ƒä»·å€¼æ˜¯"å¤šè§†è§’æƒè¡¡"
2. å¦‚æœæˆ‘ä»¬è¯•å›¾åœ¨"è°ƒç ”å…¨é¢æ€§"ä¸Šç«äº‰,ä¼šç¨€é‡Šæˆ‘ä»¬çš„å·®å¼‚åŒ–
3. æ›´å¥½çš„ç­–ç•¥æ˜¯"åœºæ™¯äº’è¡¥",ä¸æ˜¯"åŠŸèƒ½å¯¹æ ‡"

## å»ºè®®çš„äº§å“æ¼”è¿›è·¯å¾„

### ä¸è¦åš (No-Go):
- âŒ åŠ å…¥æœç´¢å¼•æ“(åç¦»å®šä½)
- âŒ åšæˆ"æ›´å…¨é¢çš„Deep Research"(æ‰“ä¸èµ¢)
- âŒ å¢åŠ å¤§é‡general features(ç¨€é‡Šfocus)

### åº”è¯¥åš (Yes-Go):
- âœ… æ·±åŒ–Context-Aware Expert Matching(æŠ¤åŸæ²³)
- âœ… æå‡Actionability(å·®å¼‚åŒ–)
- âœ… é’ˆå¯¹3ä¸ªhero scenariosåšåˆ°æè‡´
- âœ… åœ¨landing pageæ˜ç¡®è¯´"ä»€ä¹ˆæ—¶å€™ç”¨æˆ‘ä»¬ vs Deep Research"

## 6ä¸ªæœˆåçš„ç›®æ ‡çŠ¶æ€

**ç”¨æˆ·å¿ƒæ™º**:
- éœ€è¦å…¨é¢è°ƒç ” â†’ Deep Research
- éœ€è¦å¤šè§†è§’æƒè¡¡å†³ç­– â†’ Chat-with-Experts
- éœ€è¦å¿«é€Ÿç­”æ¡ˆ â†’ ChatGPT

**Metrics**:
- åœ¨hero scenariosä¸Š,NPS > Deep Research
- ç”¨æˆ·èƒ½æ¸…æ¥šè¯´å‡º"ä»€ä¹ˆæ—¶å€™ç”¨è°"
```

---

### æäº¤æ¸…å•

- [ ] `assignments/assignment4_competitive_teardown.md`
- [ ] `assignments/assignment4_feature_gap.md`
- [ ] `assignments/assignment4_strategy.md`

### è¯„åˆ†æ ‡å‡†

| ç»´åº¦ | åˆ†å€¼ |
|------|------|
| æ‹†è§£æ·±åº¦(ä¸æ˜¯è¡¨é¢å¯¹æ¯”) | 35% |
| Feature gapåˆ†æåˆç†æ€§ | 30% |
| æˆ˜ç•¥å»ºè®®å¯è¡Œæ€§ | 35% |

---

## ğŸ“š Assignment 5: Build an Evaluation Harness (é«˜çº§,16å°æ—¶)

### ä»»åŠ¡æè¿°

æ„å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–è¯„æµ‹ç³»ç»Ÿ,å¯ä»¥å¿«é€Ÿå¯¹æ¯”ä¸åŒpromptç‰ˆæœ¬çš„æ•ˆæœã€‚

### Part 1: è®¾è®¡æ¶æ„ (4h)

**éœ€æ±‚**:
1. è¾“å…¥: ä¸€ä¸ªpromptç‰ˆæœ¬ID
2. è¿è¡Œ: åœ¨100ä¸ªgolden casesä¸Šæµ‹è¯•
3. è¾“å‡º: å„ç»´åº¦åˆ†æ•° + å¯¹æ¯”baselineçš„improvement

**åˆ›å»º**: `eval/harness/ARCHITECTURE.md`

```markdown
# Evaluation Harness Architecture

## ç³»ç»Ÿè®¾è®¡

### Components

1. **Test Case Loader**
   - è¯»å–golden dataset (100ä¸ªcases)
   - Parse query, expected experts, success criteria

2. **Test Runner**
   - å¯¹æ¯ä¸ªcase,è°ƒç”¨ç³»ç»Ÿç”Ÿæˆoutput
   - è®°å½•latency, errors

3. **Judge Orchestrator**
   - è¿è¡Œæ‰€æœ‰judges (actionability, expert-match, context-matchç­‰)
   - æ±‡æ€»åˆ†æ•°

4. **Reporter**
   - ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
   - è¯†åˆ«regression cases
   - å¯è§†åŒ–(é›·è¾¾å›¾)

### Data Flow

\`\`\`
Test Cases (100)
  â†’ Test Runner (generate outputs)
  â†’ Judge Orchestrator (evaluate outputs)
  â†’ Aggregator (compute scores)
  â†’ Reporter (generate report)
\`\`\`

### æ–‡ä»¶ç»“æ„

\`\`\`
eval/
â”œâ”€â”€ harness/
â”‚   â”œâ”€â”€ runner.ts          # ä¸»è¿è¡Œå™¨
â”‚   â”œâ”€â”€ loader.ts          # åŠ è½½test cases
â”‚   â”œâ”€â”€ judgeOrchestrator.ts  # åè°ƒæ‰€æœ‰judges
â”‚   â”œâ”€â”€ reporter.ts        # ç”ŸæˆæŠ¥å‘Š
â”‚   â””â”€â”€ visualize.ts       # å¯è§†åŒ–
â”œâ”€â”€ results/
â”‚   â””â”€â”€ v2_vs_v3_vs_v4.json
â””â”€â”€ golden-dataset/
    â””â”€â”€ cases_100.json
\`\`\`
```

---

### Part 2: å®ç°æ ¸å¿ƒç»„ä»¶ (8h)

#### Task 2.1: Test Runner (3h)

```typescript
// eval/harness/runner.ts

import { loadGoldenDataset } from './loader';
import { runAllJudges } from './judgeOrchestrator';

interface EvalConfig {
  version: string;  // 'v2', 'v3', etc.
  testCases: string[];  // case IDs to test, or 'all'
  judgeWeights: {
    actionability: number;
    expertMatch: number;
    contextMatch: number;
    // ...
  };
}

interface EvalResult {
  version: string;
  timestamp: string;
  results: Array<{
    caseId: string;
    query: string;
    systemOutput: {
      experts: any[];
      dialogue: string;
    };
    scores: {
      actionability: number;
      expertMatch: number;
      contextMatch: number;
      overall: number;
    };
    latency: number;
    error?: string;
  }>;
  summary: {
    overall: number;
    actionability: number;
    expertMatch: number;
    // ...
  };
}

export async function runEvaluation(
  config: EvalConfig
): Promise<EvalResult> {
  const testCases = loadGoldenDataset(config.testCases);

  const results = [];

  for (const testCase of testCases) {
    const startTime = Date.now();

    try {
      // 1. ç”Ÿæˆoutput
      const systemOutput = await generateResponse(
        testCase.query,
        testCase.userContext,
        config.version
      );

      // 2. è¿è¡Œæ‰€æœ‰judges
      const scores = await runAllJudges({
        query: testCase.query,
        userContext: testCase.userContext,
        systemOutput: systemOutput,
      });

      // 3. è®°å½•ç»“æœ
      results.push({
        caseId: testCase.id,
        query: testCase.query,
        systemOutput: systemOutput,
        scores: scores,
        latency: Date.now() - startTime,
      });

    } catch (error) {
      results.push({
        caseId: testCase.id,
        query: testCase.query,
        error: error.message,
      });
    }
  }

  // 4. è®¡ç®—summary
  const summary = computeSummary(results, config.judgeWeights);

  return {
    version: config.version,
    timestamp: new Date().toISOString(),
    results: results,
    summary: summary,
  };
}

function computeSummary(results, weights) {
  // TODO: è®¡ç®—åŠ æƒå¹³å‡åˆ†
}
```

#### Task 2.2: Reporter (3h)

```typescript
// eval/harness/reporter.ts

interface ComparisonReport {
  baseline: EvalResult;
  treatment: EvalResult;
  comparison: {
    overallImprovement: number;  // +1.2
    dimensionImprovements: {
      actionability: number;
      expertMatch: number;
      // ...
    };
    regressionCases: string[];  // case IDs that got worse
    improvementCases: string[];  // case IDs that got better
    statisticalSignificance: boolean;  // t-test result
  };
}

export function generateComparisonReport(
  baseline: EvalResult,
  treatment: EvalResult
): ComparisonReport {
  // TODO: å®ç°å¯¹æ¯”é€»è¾‘

  // 1. è®¡ç®—overall improvement
  const overallImprovement =
    treatment.summary.overall - baseline.summary.overall;

  // 2. æ‰¾regression cases
  const regressionCases = [];
  for (let i = 0; i < baseline.results.length; i++) {
    const baseScore = baseline.results[i].scores.overall;
    const treatScore = treatment.results[i].scores.overall;
    if (treatScore < baseScore - 1.0) {  // é™ä½è¶…è¿‡1åˆ†ç®—regression
      regressionCases.push(baseline.results[i].caseId);
    }
  }

  // 3. Statistical test
  const pValue = tTest(
    baseline.results.map(r => r.scores.overall),
    treatment.results.map(r => r.scores.overall)
  );

  return {
    baseline,
    treatment,
    comparison: {
      overallImprovement,
      dimensionImprovements: { /* ... */ },
      regressionCases,
      improvementCases: /* ... */,
      statisticalSignificance: pValue < 0.05,
    },
  };
}

export function exportMarkdownReport(report: ComparisonReport): string {
  return `
# Evaluation Report: ${report.treatment.version} vs ${report.baseline.version}

## Summary

- **Overall Improvement**: ${report.comparison.overallImprovement > 0 ? '+' : ''}${report.comparison.overallImprovement.toFixed(2)}
- **Statistical Significance**: ${report.comparison.statisticalSignificance ? 'âœ… Yes (p < 0.05)' : 'âŒ No'}

## Dimension Breakdown

| Dimension | Baseline | Treatment | Delta |
|-----------|----------|-----------|-------|
| Actionability | ${report.baseline.summary.actionability.toFixed(1)} | ${report.treatment.summary.actionability.toFixed(1)} | ${/* ... */} |
| Expert Match | ... | ... | ... |

## Regression Cases (${report.comparison.regressionCases.length})

${report.comparison.regressionCases.map(caseId => {
  const baseCase = report.baseline.results.find(r => r.caseId === caseId);
  const treatCase = report.treatment.results.find(r => r.caseId === caseId);
  return `
### ${caseId}
- **Query**: ${baseCase.query}
- **Baseline Score**: ${baseCase.scores.overall}
- **Treatment Score**: ${treatCase.scores.overall}
- **Delta**: ${(treatCase.scores.overall - baseCase.scores.overall).toFixed(1)}
`;
}).join('\n')}

## Recommendation

${report.comparison.overallImprovement > 0.5 && !report.comparison.regressionCases.length
  ? 'âœ… Safe to deploy treatment version'
  : 'âš ï¸ Review regression cases before deploying'}
  `;
}
```

#### Task 2.3: CLI Interface (2h)

```bash
# è¿è¡Œå•ä¸ªç‰ˆæœ¬è¯„æµ‹
npm run eval -- --version v3 --cases all

# å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬
npm run eval:compare -- --baseline v2 --treatment v3

# åªæµ‹è¯•éƒ¨åˆ†cases
npm run eval -- --version v3 --cases case-001,case-002,case-003

# ç”ŸæˆæŠ¥å‘Š
npm run eval:report -- --baseline v2 --treatment v3 --output report.md
```

---

### Part 3: å®æˆ˜æµ‹è¯• (4h)

**ä»»åŠ¡**: ç”¨ä½ çš„harnesså¯¹æ¯”V2 vs V3

1. è¿è¡Œevaluation
2. ç”ŸæˆæŠ¥å‘Š
3. åˆ†æregression cases
4. æ’°å†™æ€»ç»“

**æäº¤**: `assignments/assignment5_eval_results.md`

```markdown
# V2 vs V3 Evaluation Results

## Test Setup
- Baseline: V2 (old prompts)
- Treatment: V3 (improved prompts after user feedback)
- Test cases: 100 golden cases
- Date: 2025-11-27

## Summary Results

| Metric | V2 | V3 | Delta | Significant? |
|--------|----|----|-------|--------------|
| Overall | 6.8 | 7.9 | +1.1 | âœ… (p=0.003) |
| Actionability | 6.2 | 8.1 | +1.9 | âœ… |
| Expert Match | 7.5 | 8.3 | +0.8 | âœ… |
| Context Match | 6.5 | 7.6 | +1.1 | âœ… |

## Key Findings

### ğŸ‰ Major Improvements
1. **Actionability +1.9**: æ–°promptçš„actionability templateèµ·ä½œç”¨äº†
2. **63% of cases improved**: 100ä¸ªcasesä¸­63ä¸ªæœ‰æå‡

### âš ï¸ Regression Cases (8ä¸ª)

**Case-007**: "æ—©æœŸåˆ›ä¸šè€…PMFéªŒè¯"
- V2 Score: 8.2 â†’ V3 Score: 7.1 (-1.1)
- **é—®é¢˜**: æ–°promptè¿‡äºå¼ºè°ƒ"å…·ä½“æ­¥éª¤",å¯¼è‡´ä¸“å®¶æ²¡æœ‰å…ˆclarifyç”¨æˆ·çš„å…·ä½“æƒ…å†µå°±ç›´æ¥ç»™æ–¹æ¡ˆ
- **ä¿®å¤å»ºè®®**: åœ¨actionability templateå‰åŠ "Clarification Phase"

**Case-023**: ...
[åˆ†æå…¶ä»–7ä¸ªregression cases]

### ğŸ’¡ Insights

1. **Actionability Template works**: å¼ºåˆ¶è¦æ±‚specific stepsç¡®å®æå‡äº†å¯æ‰§è¡Œæ€§
2. **Trade-off**: è¿‡äºå…³æ³¨actionabilityå¯èƒ½ç‰ºç‰²äº†contextual understanding
3. **Next step**: éœ€è¦å¹³è¡¡actionabilityå’Œcontext awareness

## Deployment Decision

âœ… **Recommend deploying V3**, but with following improvements:
1. ä¿®å¤case-007ç±»çš„clarificationé—®é¢˜
2. ç›‘æ§productionæ•°æ®,çœ‹æ˜¯å¦æœ‰ç±»ä¼¼regression
3. 2å‘¨åé‡æ–°è¯„æµ‹
```

---

### æäº¤æ¸…å•

- [ ] `eval/harness/` (å®Œæ•´ä»£ç )
- [ ] `assignments/assignment5_architecture.md`
- [ ] `assignments/assignment5_eval_results.md`
- [ ] å¯è¿è¡Œçš„CLIå‘½ä»¤

### è¯„åˆ†æ ‡å‡†

| ç»´åº¦ | åˆ†å€¼ |
|------|------|
| æ¶æ„è®¾è®¡åˆç†æ€§ | 25% |
| ä»£ç å®ç°è´¨é‡ | 30% |
| æŠ¥å‘Šåˆ†ææ·±åº¦ | 25% |
| å¯ç”¨æ€§(å…¶ä»–å¼€å‘è€…èƒ½ç”¨) | 20% |

---

## ğŸ“š Assignment 6: End-to-End Project (ç»¼åˆ,40å°æ—¶)

### ä»»åŠ¡æè¿°

ä»ç”¨æˆ·è®¿è°ˆåˆ°promptä¼˜åŒ–åˆ°è¯„æµ‹,å®Œæ•´èµ°ä¸€éworkflowã€‚

è¿™æ˜¯ä¸€ä¸ªç»¼åˆæ€§ä½œä¸š,æ£€éªŒä½ æ˜¯å¦æŒæ¡äº†æ•´ä¸ªagentå¼€å‘æµç¨‹ã€‚

### Week 1: å‘ç°é—®é¢˜ (16h)

- [ ] æ‹›å‹Ÿå¹¶è®¿è°ˆ5ä¸ªç”¨æˆ·
- [ ] è¯†åˆ«æœ€å¤§çš„1-2ä¸ªé—®é¢˜
- [ ] æ’°å†™problem statement

### Week 2: è®¾è®¡æ–¹æ¡ˆ (8h)

- [ ] è®¾è®¡promptæ”¹è¿›æ–¹æ¡ˆ
- [ ] å†™å‡ºexpected improvement hypothesis
- [ ] å‡†å¤‡A/B testè®¡åˆ’

### Week 3: å®ç°ä¸æµ‹è¯• (12h)

- [ ] ä¿®æ”¹prompt
- [ ] åœ¨20ä¸ªcasesä¸Šæµ‹è¯•
- [ ] è¿è¡Œevaluation harness

### Week 4: åˆ†æä¸æŠ¥å‘Š (4h)

- [ ] å¯¹æ¯”before/after
- [ ] åˆ†æregression cases
- [ ] æ’°å†™æœ€ç»ˆæŠ¥å‘Š

### æœ€ç»ˆæäº¤

`assignments/assignment6_final_report.md`:
- ç”¨æˆ·è®¿è°ˆæ‘˜è¦
- Problem statement
- è§£å†³æ–¹æ¡ˆè®¾è®¡
- å®ç°ç»†èŠ‚
- A/B testç»“æœ
- Lessons learned

**è¿™ä¸ªassignmentæ²¡æœ‰æ ‡å‡†ç­”æ¡ˆ,è¯„åˆ†å®Œå…¨åŸºäºä½ çš„workflowä¸¥è°¨æ€§å’Œæ”¹è¿›æ•ˆæœã€‚**

---

## ğŸ“ æ€»ç»“

å®Œæˆè¿™6ä¸ªassignmentså,ä½ å°†æŒæ¡:

1. **Prompt Engineering**: ä»å¤±è´¥æ¡ˆä¾‹å­¦ä¹ ,ç³»ç»Ÿæ€§ä¼˜åŒ–
2. **Evaluation Design**: æ„å»ºå¯é çš„LLM judge
3. **Data-Driven Iteration**: ç”¨æˆ·åé¦ˆ â†’ åˆ†æ â†’ æ”¹è¿› â†’ éªŒè¯çš„é—­ç¯
4. **Competitive Strategy**: å¦‚ä½•å®šä½äº§å“,ä¸ç›²ç›®å¯¹æ ‡
5. **Infrastructure**: æ„å»ºè‡ªåŠ¨åŒ–è¯„æµ‹ç³»ç»Ÿ
6. **End-to-End Execution**: å®Œæ•´çš„agentå¼€å‘workflow

**æ—¶é—´æŠ•å…¥**: ~86å°æ—¶
**å»ºè®®èŠ‚å¥**: æ¯å‘¨å®Œæˆ1-2ä¸ªassignments

**Good luck! ğŸš€**
